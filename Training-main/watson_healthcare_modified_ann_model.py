# -*- coding: utf-8 -*-
"""watson_healthcare_modified ANN Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rT8bowwh74KNecuHBxQvtF3F5mpWvc90
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from statistics import mode
import random

data= pd.read_csv('watson_healthcare_modified.csv')

data.head()

data.shape

data.info()

data.drop('EmployeeID',axis=1,inplace=True)

data.head(1)

data['Attrition'].value_counts()

data.isna().sum()

data['DailyRate']

data.drop('DailyRate',axis=1,inplace=True)

data['BusinessTravel'].unique()

data['BusinessTravel']=data['BusinessTravel'].map({'Travel_Rarely':1,'Travel_Frequently':2,'Non-Travel':0})

data['BusinessTravel'].unique()

data['Department'].unique()

data['Department']=data['Department'].map({'Cardiology':1,'Maternity':2,'Neurology':0})

data['Department'].unique()

data.head(1)

data['EducationField'].unique()

data['Gender'].unique()

data['Gender']=data['Gender'].map({'Female':1,'Male':0})

data['Gender'].unique()

data['YearsSinceLastPromotion'].unique()

data.drop('TrainingTimesLastYear',axis=1,inplace=True)

data['Shift'].unique()

data['Shift'].value_counts()

data.drop('WorkLifeBalance',axis=1,inplace=True)

data.drop('YearsWithCurrManager',axis=1,inplace=True)

data['BusinessTravel'].unique()

data.drop('BusinessTravel',axis=1,inplace=True)

data.drop('EmployeeCount',axis=1,inplace=True)

data['OverTime'].unique()

data['OverTime']=data['OverTime'].map({'Yes':1,'No':0})

data.drop('HourlyRate',axis=1,inplace=True)

data.drop('EnvironmentSatisfaction',axis=1,inplace=True)

data.head(1)

data.info()

data.drop('Over18',axis=1,inplace=True)

data['Attrition'].unique()

data['Attrition']=data['Attrition'].map({'No':0,'Yes':1})

data['Attrition'].unique()

data['Education'].unique()

data['JobRole'].unique()

data['MaritalStatus'].unique()

data['MaritalStatus'].value_counts()

data.drop('MaritalStatus',axis=1,inplace=True)

data['RelationshipSatisfaction'].unique()

data['PercentSalaryHike'].unique()

data['PerformanceRating'].unique()

data.drop('StandardHours',axis=1,inplace=True)

data.head(1)

from sklearn.preprocessing import LabelEncoder

LB= LabelEncoder()

data['EducationField']=LB.fit_transform(data['EducationField'])

data['JobRole']=LB.fit_transform(data['JobRole'])

data.dtypes

X=data.drop('Attrition',axis=True)

X.head(2)

y=data['Attrition']

y.head()

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=12)

X_train.head(2)

y_train.head()

X_test.head(2)

y_test.head()

model=keras.Sequential([
    keras.layers.Dense(50,input_shape=(22,),activation="sigmoid"),
      keras.layers.Dense(20,activation="softmax"),
      keras.layers.Dense(2,activation="sigmoid"),
    ])

model.compile(optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model.fit(X_train,y_train,epochs=10)

model.evaluate(X_train,y_train)